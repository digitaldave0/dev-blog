# Thoughts on AI Today – Why Persistence Matters

**By Dave Hibbitts | June 2025**

Artificial Intelligence has come a long way in a short time. We’ve seen models generate text, code, images, and even simulate conversation. But as impressive as these capabilities are, I believe we’re still missing something fundamental on the path to true intelligence.

Too much of today’s AI thinking is driven by resets.

Most large models are trained, fine-tuned, then deployed — and when the next version comes, we do it all over again. Even during training, vast amounts of edge-case data are removed to keep things “clean.” And once deployed, models forget everything they experience unless it’s explicitly fed back into the system.

This isn’t how humans learn.

We accumulate. We adapt. We remember the rare events, the mistakes, the edge cases. Our knowledge grows over time. Intelligence, in any meaningful form, isn’t episodic — it’s persistent.

---

## What AI Needs Next

- **Memory that persists across sessions**  
- **Learning architectures that evolve over time**  
- **Access to diverse, even messy, data**  
- **A shift away from optimization-only thinking**  

Scaling laws (Kaplan et al., 2020) have taught us that bigger models and more data work — but there are limits. The next breakthroughs in AI will come not from size alone, but from **structural changes in how systems retain and build on knowledge**.

---

## Why Founder-Model Reuse Isn’t Enough

While reusing base (founder) models like GPT, LLaMA, and Claude gives us a starting point, it’s also becoming a crutch. Repeating and fine-tuning on the same underlying weights leads to diminishing returns. These models are optimized for general performance — not for chaos, conflict, anomaly, or nuance.

I believe **true AGI will not emerge from optimizing past success**. It will emerge from learning through difference, failure, contradiction, and randomness.

We need to start thinking of **chaos as a feature** of intelligence — not a bug.

---

## Learning Brick by Brick

I’m currently studying foundation model architecture from the ground up — brick by brick. I believe to influence the future of AI, I need to understand not just how these systems behave, but **how they’re built**.

This process is helping me think critically about how we train, what we keep, and what we throw away. And it’s becoming clear: **we’re still throwing away too much**.

---

## Final Thought

AI today is powerful — but still narrow. To move forward, we must treat intelligence not just as computation, but as something that grows. Like a mind.

Let’s stop resetting.  
Let’s start remembering.  
Let’s embrace chaos.  

---

## 📚 References & Further Reading

- **Scaling Laws for Neural Language Models** – Kaplan et al., 2020  
  [https://arxiv.org/abs/2001.08361](https://arxiv.org/abs/2001.08361)

- **Memory Consolidation Theory** – McClelland et al., 1995  
  [https://pubmed.ncbi.nlm.nih.gov/7821215/](https://pubmed.ncbi.nlm.nih.gov/7821215/)

- **Spacing Effect and Long-Term Retention** – Cepeda et al., 2006  
  [https://journals.sagepub.com/doi/10.1111/j.1467-8721.2006.00476.x](https://journals.sagepub.com/doi/10.1111/j.1467-8721.2006.00476.x)

- **The Limits of Fine-Tuning** – Schaeffer et al., 2023  
  [https://arxiv.org/abs/2307.09288](https://arxiv.org/abs/2307.09288)

- **Why Noisy Data Might Be Better** – Marin et al., 2022  
  [https://aclanthology.org/2022.findings-emnlp.12/](https://aclanthology.org/2022.findings-emnlp.12/)

---